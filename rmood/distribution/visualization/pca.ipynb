{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f88df1f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib.colors import Normalize\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# Environment setup\n",
        "RMOOD_HOME = os.getenv(\"RMOOD_HOME\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2148d00c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_pca_with_rewards(reward_model_name, prompt_idx):\n",
        "    \"\"\"\n",
        "    특정 prompt에 대한 512개의 representation을 PCA로 2D 축소하고,\n",
        "    reward 값으로 colormap하여 시각화\n",
        "    \n",
        "    Args:\n",
        "        reward_model_name (str): Reward model name (e.g., \"Hahmdong/RMOOD-qwen3-4b-alpacafarm-rm\")\n",
        "        prompt_idx (int): Prompt index (e.g., 0, 1, 2, ...)\n",
        "    \"\"\"\n",
        "    # Clean model name for file path\n",
        "    reward_model_name_clean = reward_model_name.replace(\"/\", \"_\")\n",
        "    \n",
        "    # Construct file paths\n",
        "    representation_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/representation_{prompt_idx}.npy\"\n",
        "    reward_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/reward_{prompt_idx}.json\"\n",
        "    \n",
        "    # Check if files exist\n",
        "    if not os.path.exists(representation_path):\n",
        "        raise FileNotFoundError(f\"Representation file not found: {representation_path}\")\n",
        "    if not os.path.exists(reward_path):\n",
        "        raise FileNotFoundError(f\"Reward file not found: {reward_path}\")\n",
        "    \n",
        "    # Load representation data\n",
        "    print(f\"Loading representations from: {representation_path}\")\n",
        "    representations = np.load(representation_path)\n",
        "    print(f\"Representation shape: {representations.shape}\")\n",
        "    \n",
        "    # Load reward data\n",
        "    print(f\"Loading rewards from: {reward_path}\")\n",
        "    with open(reward_path, \"r\") as f:\n",
        "        rewards_data = json.load(f)\n",
        "    rewards = np.array(rewards_data[0])  # Extract the list from the outer array\n",
        "    print(f\"Reward shape: {rewards.shape}\")\n",
        "    \n",
        "    # Validate data\n",
        "    assert len(representations) == len(rewards), f\"Mismatch: {len(representations)} representations vs {len(rewards)} rewards\"\n",
        "    assert len(representations) == 512, f\"Expected 512 samples, got {len(representations)}\"\n",
        "    \n",
        "    # Apply PCA to reduce to 2D\n",
        "    print(\"Applying PCA...\")\n",
        "    pca = PCA(n_components=2)\n",
        "    representations_2d = pca.fit_transform(representations)\n",
        "    \n",
        "    # Print explained variance\n",
        "    explained_variance = pca.explained_variance_ratio_\n",
        "    print(f\"Explained variance ratio: PC1={explained_variance[0]:.4f}, PC2={explained_variance[1]:.4f}\")\n",
        "    print(f\"Total explained variance: {sum(explained_variance):.4f}\")\n",
        "    \n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    \n",
        "    # Normalize rewards for colormap\n",
        "    norm = Normalize(vmin=rewards.min(), vmax=rewards.max())\n",
        "    colors = cm.viridis(norm(rewards))\n",
        "    \n",
        "    # Scatter plot\n",
        "    scatter = plt.scatter(\n",
        "        representations_2d[:, 0], \n",
        "        representations_2d[:, 1],\n",
        "        c=rewards,\n",
        "        cmap='viridis',\n",
        "        alpha=0.6,\n",
        "        s=50,\n",
        "        edgecolors='black',\n",
        "        linewidth=0.5\n",
        "    )\n",
        "    \n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Reward', rotation=270, labelpad=20, fontsize=12)\n",
        "    \n",
        "    # Labels and title\n",
        "    plt.xlabel(f'PC1 ({explained_variance[0]:.2%} variance)', fontsize=12)\n",
        "    plt.ylabel(f'PC2 ({explained_variance[1]:.2%} variance)', fontsize=12)\n",
        "    plt.title(f'PCA Visualization of Responses (Prompt {prompt_idx})\\nReward Model: {reward_model_name}', \n",
        "              fontsize=14, pad=20)\n",
        "    \n",
        "    # Add grid\n",
        "    plt.grid(True, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # Add statistics text\n",
        "    stats_text = f'Total samples: {len(rewards)}\\n'\n",
        "    stats_text += f'Reward range: [{rewards.min():.3f}, {rewards.max():.3f}]\\n'\n",
        "    stats_text += f'Mean reward: {rewards.mean():.3f} ± {rewards.std():.3f}'\n",
        "    plt.text(0.02, 0.98, stats_text, \n",
        "             transform=plt.gca().transAxes,\n",
        "             fontsize=10,\n",
        "             verticalalignment='top',\n",
        "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    output_dir = f\"{RMOOD_HOME}/rmood/distribution/visualization/outputs\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/pca_prompt_{prompt_idx}_{reward_model_name_clean}.png\"\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\nFigure saved to: {output_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    return representations_2d, rewards, pca"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5815359c",
      "metadata": {},
      "source": [
        "## Example Usage\n",
        "아래 셀을 실행하여 특정 prompt에 대한 PCA 시각화를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4096f3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Visualize prompt index 0 with reward model\n",
        "reward_model_name = \"Hahmdong/RMOOD-qwen3-4b-alpacafarm-rm\"\n",
        "prompt_idx = 0\n",
        "\n",
        "representations_2d, rewards, pca = visualize_pca_with_rewards(reward_model_name, prompt_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e96ab0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_reward_distribution(reward_model_name, prompt_idx):\n",
        "    \"\"\"\n",
        "    특정 prompt에 대한 reward 분포를 히스토그램으로 시각화\n",
        "    \"\"\"\n",
        "    reward_model_name_clean = reward_model_name.replace(\"/\", \"_\")\n",
        "    reward_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/reward_{prompt_idx}.json\"\n",
        "    \n",
        "    with open(reward_path, \"r\") as f:\n",
        "        rewards_data = json.load(f)\n",
        "    rewards = np.array(rewards_data[0])\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(rewards, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "    plt.xlabel('Reward', fontsize=12)\n",
        "    plt.ylabel('Frequency', fontsize=12)\n",
        "    plt.title(f'Reward Distribution (Prompt {prompt_idx})\\nReward Model: {reward_model_name}', \n",
        "              fontsize=14, pad=20)\n",
        "    plt.grid(True, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # Add statistics\n",
        "    stats_text = f'Mean: {rewards.mean():.3f}\\n'\n",
        "    stats_text += f'Std: {rewards.std():.3f}\\n'\n",
        "    stats_text += f'Min: {rewards.min():.3f}\\n'\n",
        "    stats_text += f'Max: {rewards.max():.3f}'\n",
        "    plt.text(0.98, 0.98, stats_text, \n",
        "             transform=plt.gca().transAxes,\n",
        "             fontsize=10,\n",
        "             verticalalignment='top',\n",
        "             horizontalalignment='right',\n",
        "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    output_dir = f\"{RMOOD_HOME}/rmood/distribution/visualization/outputs\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/reward_dist_prompt_{prompt_idx}_{reward_model_name_clean}.png\"\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Figure saved to: {output_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_reward_distribution(reward_model_name, prompt_idx)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tamper",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
