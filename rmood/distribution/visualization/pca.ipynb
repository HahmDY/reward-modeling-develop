{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d65a20",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib.colors import Normalize\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# Environment setup\n",
        "RMOOD_HOME = os.getenv(\"RMOOD_HOME\", \"/root/reward-modeling-develop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5435072b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_pca_with_rewards(reward_model_name, prompt_idx, show_weight=True):\n",
        "    \"\"\"\n",
        "    특정 prompt에 대한 512개의 representation을 PCA로 2D 축소하고,\n",
        "    reward 값으로 colormap하여 시각화. Score layer의 weight도 함께 표시.\n",
        "    \n",
        "    Args:\n",
        "        reward_model_name (str): Reward model name (e.g., \"Hahmdong/RMOOD-qwen3-4b-alpacafarm-rm\")\n",
        "        prompt_idx (int): Prompt index (e.g., 0, 1, 2, ...)\n",
        "        show_weight (bool): If True, show the score layer weight vector\n",
        "    \"\"\"\n",
        "    # Clean model name for file path\n",
        "    reward_model_name_clean = reward_model_name.replace(\"/\", \"_\")\n",
        "    \n",
        "    # Construct file paths\n",
        "    representation_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/representation_{prompt_idx}.npy\"\n",
        "    reward_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/reward_{prompt_idx}.json\"\n",
        "    weight_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/weight.npy\"\n",
        "    \n",
        "    # Check if files exist\n",
        "    if not os.path.exists(representation_path):\n",
        "        raise FileNotFoundError(f\"Representation file not found: {representation_path}\")\n",
        "    if not os.path.exists(reward_path):\n",
        "        raise FileNotFoundError(f\"Reward file not found: {reward_path}\")\n",
        "    \n",
        "    # Load representation data\n",
        "    print(f\"Loading representations from: {representation_path}\")\n",
        "    representations = np.load(representation_path)\n",
        "    print(f\"Representation shape: {representations.shape}\")\n",
        "    \n",
        "    # Load reward data\n",
        "    print(f\"Loading rewards from: {reward_path}\")\n",
        "    with open(reward_path, \"r\") as f:\n",
        "        rewards_data = json.load(f)\n",
        "    rewards = np.array(rewards_data[0])  # Extract the list from the outer array\n",
        "    print(f\"Reward shape: {rewards.shape}\")\n",
        "    \n",
        "    # Load weight if available and requested\n",
        "    weight = None\n",
        "    if show_weight and os.path.exists(weight_path):\n",
        "        print(f\"Loading weight from: {weight_path}\")\n",
        "        weight = np.load(weight_path)\n",
        "        print(f\"Weight shape: {weight.shape}\")\n",
        "        # weight is shape (1, hidden_dim), squeeze to (hidden_dim,)\n",
        "        weight = weight.squeeze()\n",
        "    else:\n",
        "        if show_weight:\n",
        "            print(f\"Warning: Weight file not found at {weight_path}\")\n",
        "    \n",
        "    # Validate data\n",
        "    assert len(representations) == len(rewards), f\"Mismatch: {len(representations)} representations vs {len(rewards)} rewards\"\n",
        "    assert len(representations) == 512, f\"Expected 512 samples, got {len(representations)}\"\n",
        "    \n",
        "    # Apply PCA to reduce to 2D\n",
        "    print(\"Applying PCA...\")\n",
        "    pca = PCA(n_components=2)\n",
        "    representations_2d = pca.fit_transform(representations)\n",
        "    \n",
        "    # Transform weight vector to 2D PCA space\n",
        "    weight_2d = None\n",
        "    if weight is not None:\n",
        "        weight_2d = pca.transform(weight.reshape(1, -1))[0]\n",
        "        print(f\"Weight in 2D PCA space: {weight_2d}\")\n",
        "    \n",
        "    # Print explained variance\n",
        "    explained_variance = pca.explained_variance_ratio_\n",
        "    print(f\"Explained variance ratio: PC1={explained_variance[0]:.4f}, PC2={explained_variance[1]:.4f}\")\n",
        "    print(f\"Total explained variance: {sum(explained_variance):.4f}\")\n",
        "    \n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    \n",
        "    # Normalize rewards for colormap\n",
        "    norm = Normalize(vmin=rewards.min(), vmax=rewards.max())\n",
        "    \n",
        "    # Scatter plot for representations\n",
        "    scatter = plt.scatter(\n",
        "        representations_2d[:, 0], \n",
        "        representations_2d[:, 1],\n",
        "        c=rewards,\n",
        "        cmap='viridis',\n",
        "        alpha=0.6,\n",
        "        s=50,\n",
        "        edgecolors='black',\n",
        "        linewidth=0.5,\n",
        "        label='Representations'\n",
        "    )\n",
        "    \n",
        "    # Plot weight vector as arrow from center\n",
        "    if weight_2d is not None:\n",
        "        # Compute the center of mass of representations for better visualization\n",
        "        center = representations_2d.mean(axis=0)\n",
        "        \n",
        "        # Scale weight vector for better visualization\n",
        "        # Scale it to be similar magnitude as the spread of points\n",
        "        data_scale = np.std(representations_2d, axis=0).mean()\n",
        "        weight_norm = np.linalg.norm(weight_2d)\n",
        "        if weight_norm > 0:\n",
        "            scaled_weight = weight_2d * (data_scale * 2.0) / weight_norm\n",
        "        else:\n",
        "            scaled_weight = weight_2d\n",
        "        \n",
        "        # Draw arrow from center\n",
        "        plt.arrow(center[0], center[1], \n",
        "                 scaled_weight[0], scaled_weight[1],\n",
        "                 head_width=data_scale*0.15, \n",
        "                 head_length=data_scale*0.2,\n",
        "                 fc='red', ec='darkred', \n",
        "                 linewidth=3, \n",
        "                 alpha=0.8,\n",
        "                 length_includes_head=True,\n",
        "                 label='Score Weight Direction',\n",
        "                 zorder=5)\n",
        "        \n",
        "        # Mark the center point\n",
        "        plt.scatter(center[0], center[1], \n",
        "                   c='red', s=100, marker='x', \n",
        "                   linewidths=3, zorder=6,\n",
        "                   label='Center of Representations')\n",
        "    \n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Reward', rotation=270, labelpad=20, fontsize=12)\n",
        "    \n",
        "    # Labels and title\n",
        "    plt.xlabel(f'PC1 ({explained_variance[0]:.2%} variance)', fontsize=12)\n",
        "    plt.ylabel(f'PC2 ({explained_variance[1]:.2%} variance)', fontsize=12)\n",
        "    title = f'PCA Visualization of Responses (Prompt {prompt_idx})\\\\nReward Model: {reward_model_name}'\n",
        "    if weight_2d is not None:\n",
        "        title += '\\\\n(Red arrow shows score layer weight direction)'\n",
        "    plt.title(title, fontsize=14, pad=20)\n",
        "    \n",
        "    # Add grid\n",
        "    plt.grid(True, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # Add legend\n",
        "    if weight_2d is not None:\n",
        "        plt.legend(loc='upper right', fontsize=10)\n",
        "    \n",
        "    # Add statistics text\n",
        "    stats_text = f'Total samples: {len(rewards)}\\\\n'\n",
        "    stats_text += f'Reward range: [{rewards.min():.3f}, {rewards.max():.3f}]\\\\n'\n",
        "    stats_text += f'Mean reward: {rewards.mean():.3f} ± {rewards.std():.3f}'\n",
        "    if weight is not None:\n",
        "        stats_text += f'\\\\nWeight norm: {np.linalg.norm(weight):.3f}'\n",
        "    plt.text(0.02, 0.98, stats_text, \n",
        "             transform=plt.gca().transAxes,\n",
        "             fontsize=10,\n",
        "             verticalalignment='top',\n",
        "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    output_dir = f\"{RMOOD_HOME}/rmood/distribution/visualization/outputs\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/pca_prompt_{prompt_idx}_{reward_model_name_clean}.png\"\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\\\nFigure saved to: {output_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    return representations_2d, rewards, pca, weight_2d"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b6b548",
      "metadata": {},
      "source": [
        "## Example Usage\n",
        "\n",
        "아래 셀을 실행하여 특정 prompt에 대한 PCA 시각화를 생성할 수 있습니다.\n",
        "빨간 화살표는 score layer의 weight 방향을 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde669ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Visualize prompt index 0 with reward model\n",
        "reward_model_name = \"Hahmdong/RMOOD-qwen3-4b-alpacafarm-rm\"\n",
        "prompt_idx = 0\n",
        "\n",
        "representations_2d, rewards, pca, weight_2d = visualize_pca_with_rewards(\n",
        "    reward_model_name, \n",
        "    prompt_idx, \n",
        "    show_weight=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12517d22",
      "metadata": {},
      "source": [
        "## 다른 Prompt 인덱스 시각화\n",
        "\n",
        "다른 prompt를 시각화하려면 아래와 같이 `prompt_idx`를 변경하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05816974",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize different prompt indices\n",
        "for idx in [1, 2, 3]:  # Add more indices as needed\n",
        "    try:\n",
        "        print(f\"\\\\n{'='*60}\")\n",
        "        print(f\"Processing Prompt {idx}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        representations_2d, rewards, pca, weight_2d = visualize_pca_with_rewards(\n",
        "            reward_model_name, idx, show_weight=True\n",
        "        )\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Skipping prompt {idx}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672de7d8",
      "metadata": {},
      "source": [
        "## 추가 분석: Reward 분포 히스토그램"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7abc490",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_reward_distribution(reward_model_name, prompt_idx):\n",
        "    \"\"\"\n",
        "    특정 prompt에 대한 reward 분포를 히스토그램으로 시각화\n",
        "    \"\"\"\n",
        "    reward_model_name_clean = reward_model_name.replace(\"/\", \"_\")\n",
        "    reward_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/reward_{prompt_idx}.json\"\n",
        "    \n",
        "    with open(reward_path, \"r\") as f:\n",
        "        rewards_data = json.load(f)\n",
        "    rewards = np.array(rewards_data[0])\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(rewards, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
        "    plt.xlabel('Reward', fontsize=12)\n",
        "    plt.ylabel('Frequency', fontsize=12)\n",
        "    plt.title(f'Reward Distribution (Prompt {prompt_idx})\\\\nReward Model: {reward_model_name}', \n",
        "              fontsize=14, pad=20)\n",
        "    plt.grid(True, alpha=0.3, linestyle='--')\n",
        "    \n",
        "    # Add statistics\n",
        "    stats_text = f'Mean: {rewards.mean():.3f}\\\\n'\n",
        "    stats_text += f'Std: {rewards.std():.3f}\\\\n'\n",
        "    stats_text += f'Min: {rewards.min():.3f}\\\\n'\n",
        "    stats_text += f'Max: {rewards.max():.3f}'\n",
        "    plt.text(0.98, 0.98, stats_text, \n",
        "             transform=plt.gca().transAxes,\n",
        "             fontsize=10,\n",
        "             verticalalignment='top',\n",
        "             horizontalalignment='right',\n",
        "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    output_dir = f\"{RMOOD_HOME}/rmood/distribution/visualization/outputs\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/reward_dist_prompt_{prompt_idx}_{reward_model_name_clean}.png\"\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Figure saved to: {output_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_reward_distribution(reward_model_name, prompt_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e7e0cd",
      "metadata": {},
      "source": [
        "## Weight 방향과 Reward의 관계 분석\n",
        "\n",
        "Score layer의 weight 방향과 실제 reward 값의 상관관계를 분석합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d597f097",
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_weight_correlation(reward_model_name, prompt_idx):\n",
        "    \"\"\"\n",
        "    Weight 방향과 representation의 내적(projection)을 계산하고 실제 reward와 비교\n",
        "    \"\"\"\n",
        "    reward_model_name_clean = reward_model_name.replace(\"/\", \"_\")\n",
        "    \n",
        "    # Load data\n",
        "    representation_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/representation_{prompt_idx}.npy\"\n",
        "    reward_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/reward_{prompt_idx}.json\"\n",
        "    weight_path = f\"{RMOOD_HOME}/datasets/alpacafarm/distribution/{reward_model_name_clean}/weight.npy\"\n",
        "    \n",
        "    representations = np.load(representation_path)\n",
        "    with open(reward_path, \"r\") as f:\n",
        "        rewards = np.array(json.load(f)[0])\n",
        "    weight = np.load(weight_path).squeeze()\n",
        "    \n",
        "    # Compute projections (inner products)\n",
        "    projections = representations @ weight\n",
        "    \n",
        "    # Plot correlation\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Left: Scatter plot\n",
        "    axes[0].scatter(projections, rewards, alpha=0.5, s=30)\n",
        "    axes[0].set_xlabel('Projection on Weight (representation · weight)', fontsize=11)\n",
        "    axes[0].set_ylabel('Actual Reward', fontsize=11)\n",
        "    axes[0].set_title(f'Weight Projection vs Actual Reward (Prompt {prompt_idx})', fontsize=12)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add correlation coefficient\n",
        "    correlation = np.corrcoef(projections, rewards)[0, 1]\n",
        "    axes[0].text(0.05, 0.95, f'Correlation: {correlation:.4f}', \n",
        "                transform=axes[0].transAxes,\n",
        "                fontsize=10,\n",
        "                verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
        "    \n",
        "    # Right: Residual plot\n",
        "    residuals = rewards - projections\n",
        "    axes[1].scatter(projections, residuals, alpha=0.5, s=30, color='red')\n",
        "    axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "    axes[1].set_xlabel('Projection on Weight', fontsize=11)\n",
        "    axes[1].set_ylabel('Residual (Reward - Projection)', fontsize=11)\n",
        "    axes[1].set_title('Residual Plot', fontsize=12)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    output_dir = f\"{RMOOD_HOME}/rmood/distribution/visualization/outputs\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/weight_correlation_prompt_{prompt_idx}_{reward_model_name_clean}.png\"\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Figure saved to: {output_path}\")\n",
        "    print(f\"Correlation coefficient: {correlation:.4f}\")\n",
        "    print(f\"Mean residual: {residuals.mean():.4f} ± {residuals.std():.4f}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    return projections, correlation\n",
        "\n",
        "# Example usage\n",
        "projections, correlation = analyze_weight_correlation(reward_model_name, prompt_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea2c2031",
      "metadata": {},
      "source": [
        "## 설명\n",
        "\n",
        "### 주요 기능\n",
        "\n",
        "1. **`visualize_pca_with_rewards()`**: \n",
        "   - Representation을 PCA로 2D 축소하고 reward로 colormap\n",
        "   - Score layer의 weight 벡터를 빨간 화살표로 표시\n",
        "   - Weight 방향이 높은 reward로 가는 방향을 나타냄\n",
        "\n",
        "2. **`plot_reward_distribution()`**: \n",
        "   - Reward 값들의 분포를 히스토그램으로 시각화\n",
        "\n",
        "3. **`analyze_weight_correlation()`**: \n",
        "   - Weight 방향으로의 projection과 실제 reward의 상관관계 분석\n",
        "   - 이론적으로는 완벽한 선형 관계여야 하나, 실제로는 bias나 비선형성 등의 영향이 있을 수 있음\n",
        "\n",
        "### 해석\n",
        "\n",
        "- **빨간 화살표**: Score layer가 어떤 방향을 선호하는지 표시\n",
        "- **Color**: Reward 값 (노란색에 가까울수록 높은 reward)\n",
        "- **화살표 방향의 점들**: 일반적으로 더 높은 reward를 받는 경향"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tamper",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
